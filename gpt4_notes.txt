The provided code itself doesn't seem to have a definite issue causing the doubling of VRAM usage. VRAM usage is not directly controlled by the code but by the underlying deep learning framework (like PyTorch or TensorFlow) and the hardware (GPU).

However, here are some possible reasons why you may be experiencing an unexpected increase in VRAM usage:

1. Duplicate Variables: If the Python process doesn't exit completely, the model or other variables could still be stored in memory, causing the VRAM usage to be higher than expected.

2. Evaluation Mode: Some models, when put in training mode, might consume more memory due to additional parameters required for backpropagation and gradient calculations. Ensure that the models are in evaluation mode by calling `self.model.eval()` after loading the model.

3. Batch Size: Large inputs/batch sizes may cause unexpectedly high memory usage. While in your case, you appear to use only single `prompt` for prediction at a time, you should still beware of this in the future.

4. Multiple GPU: If you have multiple GPUs and PyTorch is using more than one, it could increase the total VRAM usage.

5. Other Processes: Check if other processes or users have occupied GPU memory.

If none of the above reasons apply, then it's likely due to the inherent memory requirements of the model or transformer library. The 'vicuna-7b-v1.3' model might be a large model and may inherently require a lot of VRAM plus additional overhead. This can also depend on the PyTorch version and the machine's configuration.